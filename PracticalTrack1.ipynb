{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b0bc6f",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Welcome to the Pygame Modelling Workshop. You can find the track and tasks in this notebook. We assume that you have `python3.7+` with `pip` installed and you have installed the provided package `pygmodw25` with all it's dependencies in a virtual environment (venv) from which you are running this notebook. In case you have not yet done the preparatory steps, please follow the instructions [in the README file](https://github.com/mezdahun/PygameModelling25#1-prerequisites)\n",
    "\n",
    "## Goal of the Workshop\n",
    "During this workshop you will get a hands-on introduction and demonstration on modelling a typical multi-agent system using an open-source game engine (pygame). \n",
    "\n",
    "The main goals of this workshop is to:\n",
    "1. Learn how typical agent-based models are build into simulation fameworks. (Definition of agent, simulation, bottom-up modeling)\n",
    "2. Learn the code structure of a typical python package and modify it to build our own models\n",
    "3. Learn about typical zonal (distance-dependent) flocking models of collective motion\n",
    "4. Implement such a flocking model in pygame \n",
    "5. Interact with the model through the game engine and explore it's behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de038d",
   "metadata": {},
   "source": [
    "## Codebase\n",
    "I have initialized a basic python package with 3 simple files containing the structure for our agent-based simulation within the pygmodw25 folder. Whatever you change within those files, will first need to be installed via `pip` to include in the code within this notebook. In this section we learn how the package is built and how we can change it's behavior for our purposes.\n",
    "\n",
    "### What's inside pygmodw25?\n",
    "* The `__init__.py` file tells python that this is a module (package) that (after installation) can be imported within our won code.\n",
    "* In `agent.py` we describe the individual agents of our model. These you can think of as individual \"animals\" in a group. Here you can define their individual capabilites, appearance and behavior. This file also holds most interaction rules between agents (social interactions). Agent-based modeling is also called \"bottom up\", because we model collective behavior starting with the lowest building blocks and first principles (i.e., the individuals within the group). Top-down models, on the other hand, usually work with some statistical summaries about the system and their changes. Do you know about any top-down models?\n",
    "* In `sims.py` we describe the world and it's temporal evolution in which our agents exist. You can think of it as the rules of the world that the agents must obey. It can also include some (but not all) interaction rules between agents that are environment specific, for example collision rules (what happens if 2 agents overlap in space and time). In other words, think of this file as what is the basic physical laws in your virtual world.\n",
    "* `support.py` includes all supllementary and mathematical methods needed for the update process. These are, for example, calculation of euclidian distance, implementation of the sigmoid function, etc.\n",
    "\n",
    "### What's inside the individual files?\n",
    "In both `agent.py` and `sims.py` you will find 2 main classes. These are `AgentBase` and `Simulation`. Due to the short time we have, I prepared these with some basic functionalities. During the class we go through these shortly together. \n",
    "\n",
    "### How we define the agents?\n",
    "Let's see some examples to what's inside the `AgentBase` file.\n",
    "* the `__init__` function always initializes a given class. It gives it's base attributes, in our case each agent has an ID, certain radius (as they are circular, like pacman), color, speed and orientation in the 2D world we create. Then at the end of this fucntion we visualize the agent using pygame within the world.\n",
    "* this class also has some handy function already implemented for you, for example changing it's color, moving with the cursor in the window, get reflected from the walls of the arena (if any), etc.\n",
    "* the most important function of this class is the `update` method which is called in every simulation step and it defines how agents behave. This is where you have to integrate your theoretical model. In other words, this is where you calculate, in each simulation step, how the agent must change it's internal state (velocity, turning rate, position, orientation, etc.) given the state of the environment (in our case usually the state of other agents).\n",
    "* The current implementation is as follows:\n",
    "\n",
    "```python\n",
    "def update(self, agents):\n",
    "    \"\"\"\n",
    "    main update method of the agent. This method is called in every timestep to calculate the new state/position\n",
    "    of the agent and visualize it in the environment\n",
    "    :param agents: a list of all other agents in the environment.\n",
    "    \"\"\"\n",
    "    if not self.is_moved_with_cursor:  # we freeze agents when we move them\n",
    "        # # updating agent's state variables according to calculated vel and theta\n",
    "        self.orientation += self.dt * self.dtheta\n",
    "        self.prove_orientation()  # bounding orientation into 0 and 2pi\n",
    "        self.velocity += self.dt * self.dv\n",
    "        self.prove_velocity()  # possibly bounding velocity of agent\n",
    "\n",
    "        # updating agent's position\n",
    "        self.vx = self.velocity * np.cos(self.orientation)\n",
    "        self.vy = self.velocity * np.sin(self.orientation)\n",
    "        self.position[0] += self.vx\n",
    "        self.position[1] -= self.vy\n",
    "\n",
    "        # boundary conditions if applicable\n",
    "        self.reflect_from_walls(self.boundary)\n",
    "\n",
    "    # updating agent visualization\n",
    "    self.draw_update()\n",
    "```\n",
    "\n",
    "This method recieves all other agents data in the virtual world (this is the input of the method) and updates the focal agent (to which this method belongs to) accordingly. Currently, the agent does not interact with others and just moves in a straight line.\n",
    "\n",
    "### How we define the simulation?\n",
    "Similarly, some basic simulation features (such as building a rectangular world and adding agents to it) has been implemented for your convenience in the `Simulation` class of the `sims.py` file. At the end of the `__init__` method we initialize the pygame environment (the game engine) and create the agents within the world:\n",
    "\n",
    "```python\n",
    "# Initializing pygame\n",
    "pygame.init()\n",
    "\n",
    "# pygame related class attributes\n",
    "self.agents = pygame.sprite.Group()\n",
    "# Creating N agents in the environment\n",
    "self.create_agents()\n",
    "self.screen = pygame.display.set_mode([self.WIDTH + 2 * self.window_pad, self.HEIGHT + 2 * self.window_pad])\n",
    "self.clock = pygame.time.Clock()\n",
    "```\n",
    "\n",
    "Within this class the most important method that iterates through timesteps and updates the agents within the world is the `start` method. Here is the current implementation:\n",
    "\n",
    "```python\n",
    "def start(self):\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print(f\"Running simulation start method!\")\n",
    "\n",
    "    print(\"Starting main simulation loop!\")\n",
    "    # Main Simulation loop until dedicated simulation time\n",
    "    while self.t < self.T:\n",
    "\n",
    "        events = pygame.event.get()\n",
    "        # Carry out interaction according to user activity\n",
    "        self.interact_with_event(events)\n",
    "\n",
    "        if not self.is_paused:\n",
    "\n",
    "            if self.physical_collision_avoidance:\n",
    "                # ------ AGENT-AGENT INTERACTION ------\n",
    "                # Check if any 2 agents has been collided and reflect them from each other if so\n",
    "                collision_group_aa = pygame.sprite.groupcollide(\n",
    "                    self.agents,\n",
    "                    self.agents,\n",
    "                    False,\n",
    "                    False,\n",
    "                    within_group_collision\n",
    "                )\n",
    "                collided_agents = []\n",
    "                # Carry out agent-agent collisions and collecting collided agents for later (according to parameters\n",
    "                # such as ghost mode, or teleportation)\n",
    "                for agent1, agent2 in collision_group_aa.items():\n",
    "                    self.agent_agent_collision(agent1, agent2)\n",
    "\n",
    "            # Updating behavior of all agents within the simulation\n",
    "            for agent in self.agents:\n",
    "                agent.update(self.agents)\n",
    "\n",
    "            # Update agents according to current visible obstacles\n",
    "            self.agents.update(self.agents)\n",
    "\n",
    "            # move to next simulation timestep\n",
    "            self.t += 1\n",
    "\n",
    "        # Saving data to memory\n",
    "        if self.memory_length > 0:\n",
    "            self.save_data()\n",
    "\n",
    "        # Draw environment and agents\n",
    "        if self.with_visualization:\n",
    "            self.draw_frame()\n",
    "            pygame.display.flip()\n",
    "\n",
    "        # Moving time forward\n",
    "        self.clock.tick(self.framerate)\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print(f\"{datetime.now().strftime('%Y-%m-%d_%H-%M-%S.%f')} Total simulation time: \",\n",
    "          (end_time - start_time).total_seconds())\n",
    "\n",
    "    pygame.quit()\n",
    "```\n",
    "\n",
    "In a nutshell, we do the following:\n",
    "* we create a loop that goes from zero until `T` (note `self.T` given that we are within a class)\n",
    "* in each iteration we check if there is any interactive events in the pygame window and carry out some interactions accordingly (more about this later)\n",
    "* Then we carry out collisions between the agents (if applicable)\n",
    "* and update each agent according to the state of the world in the current timestep\n",
    "* then we iterate again and update the visualization.\n",
    "* at the end of the simulation we quit from pygame\n",
    "\n",
    "Let's see an example simulation with 10 agents for 300 simulation timesteps. (Note that the pygame window sometimes pops up behind your active window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124c0ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Running simulation start method!\n",
      "Starting main simulation loop!\n",
      "2025-07-15_10-15-34.610425 Total simulation time:  6.070245\n"
     ]
    }
   ],
   "source": [
    "# first we import our package so that we can use the classes that are defined there\n",
    "from pygmodw25.sims import Simulation\n",
    "\n",
    "# Creating a short test simulation instance with 15 agents and 150 timestep simulation time\n",
    "test_simulation = Simulation(N=10, T=150)\n",
    "\n",
    "# Start the simulation\n",
    "test_simulation.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1144d744",
   "metadata": {},
   "source": [
    "## Interactions\n",
    "pygame is a game engine, and allows user interactions with your simulations. For your convenience we defined a few within the `interact_with_event` method of the `Simulation` class. These are:\n",
    "\n",
    "**Keystrokes:**\n",
    "\n",
    "- `f`aster: increase framerate (if your system allows)\n",
    "- `s`lower: decrease framerate\n",
    "- `d`efault: default framerate (25fps)\n",
    "- `c`olor: turn on/off coloration according to agent orientation and velocity\n",
    "- `space`: pause/continue simulation\n",
    "\n",
    "**Cursor Events**:\n",
    "\n",
    "- **move**: You can drag and drop agents around by clicking and holding them. This allows you to perturb the system without any need of coding.\n",
    "- **rotate**: You can rotate the agents by first grabbing them and then using your mouse wheel (or scrolling event). In case you are using a laptop without a mouse, you can use the left and right arrows to rotate the agents **while** holding the agent with your left mouse button. Alternatively you can use scrolling **without** holding the agents with your left mouse button (first pause the simulation, then move your cursor above the agent and scroll without clicking).\n",
    "\n",
    "Let's try a few of these here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03f96d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation start method!\n",
      "Starting main simulation loop!\n",
      "Bye bye!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Desktop\\PygameModelling25\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# first we import our package so that we can use the classes that are defined there\n",
    "from pygmodw25.sims import Simulation\n",
    "\n",
    "# Creating a short test simulation instance with 15 agents and 150 timestep simulation time\n",
    "test_simulation = Simulation(N=10, T=300)\n",
    "\n",
    "# Start the simulation\n",
    "test_simulation.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12c41fa",
   "metadata": {},
   "source": [
    "# Part I.: Modifying Agents and Simulation\n",
    "Here comes the exciting part. We need to create our own agents. To do so we will use inheritance. If you don't know anything about inheritance, I suggest you read up on it here: https://www.programiz.com/python-programming/inheritance\n",
    "\n",
    "For this workshop, the following information will suffice: It is one of the most important concepts in object-oriented programming. You can think of it, as one new class that you'd define will be copied from an old one and extended with new features. It is similar to biological inheritance, where the \"child\" often shares a lot of attributes with it's \"parent\", but also has new, unique features. Why is this beneficial? Because we don't have to reinvent the wheel every time we would like to add new features to our agents (or any other class). Instead, we simply inherit all basic features, and add a few new ones.\n",
    "\n",
    "## Exercise 1: Inheritance\n",
    "Let's see how it goes. Agent's in our framework are all initialized as blue circular pacman-like dots moving in straight lines passing through each other. Let's suppose we want these agents to have a **mood** attribute that can be either \"neutral\" or \"angry\". In the begining agents should be neutral, but, if any other agent approaches closer than 20 pixels, they should turn angry. To better visualize this change, I would like the agents to turn red from blue when they become angry, but turn back to blue once neutral again.\n",
    "\n",
    "Here is how it goes:\n",
    "* We create a new class `AngryAgent` that inherits from `AgentBase`, and change it's `__init__` method to include a new mood attribute (`self.mood`)\n",
    "* We add a method in the class that switches the agent's mood and it's color according to other agents' distances\n",
    "* We **override** the `update` method of the parent class, such that it includes our new behavioral rules instead of just passively moving straight.\n",
    "\n",
    "Here we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bb05916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# import base agent\n",
    "from pygmodw25.agent import AgentBase\n",
    "# import some predefined RGB colors from support\n",
    "from pygmodw25 import support\n",
    "import numpy as np\n",
    "\n",
    "# Create new class inheriting from pygmodw25.agent.AgentBase\n",
    "class AngryAgent(AgentBase):\n",
    "    \"\"\"\n",
    "    Agent class realizing some neurotic agents that become angry with each other once too close. :(\n",
    "    \"\"\"\n",
    "    # we recieve some attributes for the base agents and initiate the parent calss with them\n",
    "    def __init__(self, id, radius, position, orientation, env_size, color, window_pad):\n",
    "        \"\"\"\n",
    "        Initalization method of main agent class of the simulations\n",
    "\n",
    "        Base parameters:\n",
    "\n",
    "        :param id: ID of agent (int)\n",
    "        :param radius: radius of the agent in pixels\n",
    "        :param position: position of the agent bounding upper left corner in env as (x, y)\n",
    "        :param orientation: absolute orientation of the agent (0 is facing to the right)\n",
    "        :param env_size: environment size available for agents as (width, height)\n",
    "        :param color: color of the agent as (R, G, B)\n",
    "        :param window_pad: padding of the environment in simulation window in pixels\n",
    "        \"\"\"\n",
    "        # Initializing supercalss (Base Agent)\n",
    "        super().__init__(id, radius, position, orientation, env_size, color, window_pad)\n",
    "        # Now we can add the new angry-specific attribute \"mood\"\n",
    "        self.mood = \"neutral\"\n",
    "    \n",
    "    # let's now add the method that switches agents' mood and color accordingly\n",
    "    def switch_mood(self, mood):\n",
    "        self.mood = mood\n",
    "        if self.mood == \"neutral\":\n",
    "            self.color = support.BLUE\n",
    "        elif self.mood == \"angry\":\n",
    "            self.color = support.RED\n",
    "    \n",
    "    # Now let's modify the update method accordingly\n",
    "    def update(self, agents):\n",
    "        \"\"\"Updates the state of the agent according to the position of other agents\"\"\"\n",
    "        distances = []\n",
    "        for ag in agents:\n",
    "            if ag.id != self.id:\n",
    "                # calculating distances\n",
    "                dist = np.linalg.norm(np.array(self.position) - np.array(ag.position))\n",
    "                distances.append(dist)\n",
    "\n",
    "        # in case any other agent is closer than 20 pixels we get ANGRY!!!!\n",
    "        if np.min(distances) < 20:\n",
    "            self.switch_mood(\"angry\")\n",
    "        else:\n",
    "            self.switch_mood(\"neutral\")\n",
    "        \n",
    "        # After this modification we would write exactly the same as\n",
    "        # what is in the parent (or super) class, so we can just reuse\n",
    "        # these as follows instead\n",
    "        super().update(agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4651f90",
   "metadata": {},
   "source": [
    "Looking good! Now we need to create a simulation that uses these new agents. Can you guess how we are gonna do that? We use inheritance! In the new `AngrySimulation` class we want to override the parent class's `add_new_agent` method, such that it now adds angry agents and not just the original vanilla ones. Note, that since we do not introduce new attributes to this new class, only a modified method, we do not have to change the `__init__`method. Let's go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6454a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base simulation\n",
    "from pygmodw25.sims import Simulation\n",
    "\n",
    "# Create new class inheriting from pygmodw25.sims.Simulation\n",
    "class AngrySim(Simulation):\n",
    "    def add_new_agent(self, id, x, y, orient):\n",
    "        \"\"\"Adding a single NEUROTIC new agent into agent sprites\"\"\"\n",
    "        agent = AngryAgent(\n",
    "            id=id,\n",
    "            radius=self.agent_radii,\n",
    "            position=(x, y),\n",
    "            orientation=orient,\n",
    "            env_size=(self.WIDTH, self.HEIGHT),\n",
    "            color=support.BLUE,\n",
    "            window_pad=self.window_pad\n",
    "        )\n",
    "        self.agents.add(agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00dc596",
   "metadata": {},
   "source": [
    "Now let's run an `AngrySim` instance with N=30 neurotic agents and run it for 300 time steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42cb1e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation start method!\n",
      "Starting main simulation loop!\n",
      "Bye bye!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Desktop\\PygameModelling25\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "angry_sim_instance = AngrySim(N=30, T=300)\n",
    "angry_sim_instance.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ed8d64",
   "metadata": {},
   "source": [
    "They indeed sim angry when they get into traffic jams. Now let's make them swear too! To do so, we do the following:\n",
    "* we create a new swearing agent type, that inherits from the angry agents\n",
    "* we initialize this new swearing agent with some built in angry messages from which it can choose when becomes angry\n",
    "* we add a `draw_message` method to the agent to visualize this random message once angry. Note that to visualize the message on the simulation screen (the window you see when running the simulation) you have to pass the `screen` attribute of the `Simulation` class to this class method.\n",
    "* we then modify the simulation class such that it uses these new swearing type of agents\n",
    "* and we add a visualization step to the simulation class's `draw_frame` method (that renders everything in each timestep), that calls the agents' `draw_message` method to also render agent messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64ec70e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation start method!\n",
      "Starting main simulation loop!\n",
      "Bye bye!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pygame\n",
    "# import base simulation\n",
    "from pygmodw25.sims import Simulation\n",
    "\n",
    "# swearing agent inherits from angry agent which alredy has a mood swing, we just need to verbalizet this\n",
    "class SwearingAngryAgent(AngryAgent):\n",
    "    def __init__(self, id, radius, position, orientation, env_size, color, window_pad):\n",
    "        super().__init__(id, radius, position, orientation, env_size, color, window_pad)\n",
    "        # Get some angry little messages\n",
    "        self.angry_messages = [\n",
    "            \"What the heck!\", \"Are you blind?!\", \"Move it!\", \"Get lost!\", \"Seriously?!\", \"Watch it!\", \"Damn it!\", \"Zack Zack!\"\n",
    "        ]\n",
    "        # choose one for now\n",
    "        self.current_message = random.choice(self.angry_messages)\n",
    "        \n",
    "    def draw_message(self, screen):\n",
    "        '''Drawing an angry message if it is called and the agent is angry. Otherwise it chooses another random message'''\n",
    "        if self.mood == \"angry\":\n",
    "            # creating text rendering\n",
    "            font = pygame.font.Font(None, 15)\n",
    "            text_surface = font.render(self.current_message, True, (255, 50, 50))\n",
    "            text_rect = text_surface.get_rect()\n",
    "            text_rect.center = (int(self.position[0]) + 2*self.radius, int(self.position[1]) + 2*self.radius+10)\n",
    "            \n",
    "            # render text on the simulation screen that is passed\n",
    "            screen.blit(text_surface, text_rect)\n",
    "        else:\n",
    "            # choose random message if not angry at the moment\n",
    "            self.current_message = random.choice(self.angry_messages)\n",
    "            \n",
    "\n",
    "# Create new class inheriting from pygmodw25.sims.Simulation\n",
    "class AngrySim(Simulation):\n",
    "    def add_new_agent(self, id, x, y, orient):\n",
    "        \"\"\"Adding a single SWEARING NEUROTIC new agent into agents of simulation\"\"\"\n",
    "        agent = SwearingAngryAgent(\n",
    "            id=id,\n",
    "            radius=self.agent_radii,\n",
    "            position=(x, y),\n",
    "            orientation=orient,\n",
    "            env_size=(self.WIDTH, self.HEIGHT),\n",
    "            color=support.BLUE,\n",
    "            window_pad=self.window_pad,\n",
    "        )\n",
    "        self.agents.add(agent)\n",
    "    \n",
    "    def draw_frame(self):\n",
    "        \"\"\"Drawing environment, agents and every other visualization in each timestep\"\"\"\n",
    "        # almost everything is the same as in the original SImulation class, but we extend it\n",
    "        super().draw_frame()\n",
    "        # extending rendering with one additional step, calling the agents' swearing method\n",
    "        for ag in self.agents:\n",
    "            ag.draw_message(self.screen)\n",
    "        \n",
    "angry_sim_instance = AngrySim(N=30, T=300)\n",
    "angry_sim_instance.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb3257",
   "metadata": {},
   "source": [
    "Wow they are really angry now! At this point you know how to:\n",
    "* Navigate in the provided code base (AgentBase and Simulation classes, class attributes and methods, update and start methods)\n",
    "* Use the concept of inheritance for your purposes:\n",
    "    * Modify the agent and simulation classes (through inheritance) to use their base features but add new behavior to them.\n",
    "    * Run simulations that use these new features.\n",
    "    \n",
    "After this part let's use our knowledge for actual science."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18eeada",
   "metadata": {},
   "source": [
    "# Part II.: The Three-Zone-Model\n",
    "\n",
    "Here, we will explore an agent-based model for simulating collective dynamics of animals (e.g. fish schools) through the provided package and small tasks. Feel free to provide your answers in this notebook. Our main task is the exploration of collective dynamics in a 2D model, related to the Three-Zone-Model (Two-Zone-Models) [by Couzin et al.](https://www.sciencedirect.com/science/article/pii/S0022519302930651), where the interaction between individuals is governed by three basic interactions: long-range attraction, short-ranged repulsion and alignment. \n",
    "\n",
    "## Brief Introduction\n",
    "### Fundamental model\n",
    "\n",
    "The code solves a set of (stochastic) differential equation describing a set of $N$ interacting agents ($i= 1,\\dots, N$). The dynamics of each agent (in 2d) is described by the following equations of motion:\n",
    "\n",
    "$$ \\frac{d \\vec{r}_i}{dt}=\\vec{v}_i(t) $$\n",
    "$$ \\vec{v}_i(t) = {s_i\\cos(\\varphi_i(t)) \\choose s_i\\sin(\\varphi_i(t)) } $$\n",
    "$$ \\frac{d \\varphi_i}{dt} = \\frac{1}{s_i}\\left( F_{i,\\varphi} + \\eta_{i,\\varphi} \\right) $$\n",
    "\n",
    "\n",
    "Here $\\vec{r}_i$, $\\vec{v}_i$ are the Cartesian position and velocity  vectors of the focal agent, wth $s_i$ being the (constant) speed of agent $i$. Furthermore, $\\eta_{i,\\varphi}$ represents Gaussian white noise introducing randomness in the motion of individuals, and $\\vec{F}_{i,\\varphi}$ is the projections of the total social force inducing a turning behavior.\n",
    "$$ F_{i,\\varphi}=\\vec{F}_i \\cdot \\vec{u}_{\\varphi,i} = \\vec{F}_i {- s_i\\sin\\varphi_i \\choose s_i\\cos\\varphi_i } $$\n",
    "\n",
    "\n",
    "The total effective social force is a sum of three components:\n",
    "$$ \\vec{F}_i=\\vec{F}_{i,rep}+\\vec{F}_{i,alg}+\\vec{F}_{i,att} $$\n",
    "\n",
    "\n",
    "**Attraction:\n",
    "$$\\vec{F}_{i,att}=\\sum_{j \\in Neigh} +\\mu_{att}S_{att}({r}_{ji}) \\hat{r}_{ji} $$\n",
    "Repulsion:\n",
    "$$\\vec{F}_{i,rep}=\\sum_{j \\in Neigh} -\\mu_{rep}S_{rep}({r}_{ji}) \\hat{r}_{ji}$$\n",
    "Alignment:**\n",
    "$$\\vec{F}_{i,alg}=\\sum_{j \\in Neigh} \\mu_{alg}S_{alg}({r}_{ji}) (\\vec{v}_j-\\vec{v}_i)$$\n",
    "with $\\hat r = \\vec{r}/|r|$.\n",
    "\n",
    "The strength of the different interactions is set by a constant $\\mu_X$ and a sigmoid function of distance, which goes from 1 to 0, with the transition point at $r_{X,0}$ and steepness $a_{X}$:\n",
    "$$ S_X(r)=\\frac{1}{2}\\left(\\tanh(-a(r-r_{X,0})+1\\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea52e8af",
   "metadata": {},
   "source": [
    "<img src=\"data/images/scheme_ranges.png\" width='800'>\n",
    "\n",
    "**Figure1.:** Local interaction forces around an agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c755e48a",
   "metadata": {},
   "source": [
    "<img src=\"data/images/int_ranges.png\">\n",
    "\n",
    "**Figure2.:** Example of the 3 interaction zones around a focal agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a36114f",
   "metadata": {},
   "source": [
    "## Task 1.: Build a basic `ZonalAgent`\n",
    "Our first task today is to build an agent that acts according to these rules, i.e. according to certain distances (or zones) around them. The above three simple rules can be formulated in python syntax by checking the distance between individual agents and acting according to these.\n",
    "\n",
    "**Specification**:\n",
    "* Create a new `ZonalAgent` class inheriting from the `AgentBase`class\n",
    "* modify it's `__init__` method such that it accepts the parameters of the flocking model as class attributes with the following default values, that is:\n",
    "    * Interaction strengths: Attraction (self.s_att = 0.02), Repulsion (self.s_rep = 5), Alignment (self.s_alg = 8)\n",
    "    * Interaction ranges (Zones) and stepness: self.steepness_att = -0.5, self.r_att = 250, self.steepness_rep = -0.5, self.r_rep = 50, self.steepness_alg = -0.5, self.r_alg = 150\n",
    "    * Noise: self.noise_sig = 0.1\n",
    "* Create an `update_forces()` method in this class that implements the above rules. Hints below.\n",
    "* modify the agent's `update` method such that it calls this new `update_forces()` method to update the agents heading before rendering it.\n",
    "\n",
    "**Definition of Done**: Your agents act according to the above model and are able to move in a flock to a shared direction.\n",
    "\n",
    "## 🧭 Step-by-Step Guide: Implementing `update_forces()` for a Zonal Flocking Model\n",
    "\n",
    "To achieve the above goals, you must update each agent's desired **velocity** (`self.dv`) and **rotation** (`self.dtheta`) based on the position and movement of nearby agents, using three key types of social forces: **attraction**, **repulsion**, and **alignment**. Here’s how to approach it: Add an `update_forces()` method to this class, and implement the following steps:\n",
    "\n",
    "---\n",
    "### **1. Understand the Agent’s Heading vector (`heading_vec`)**\n",
    "\n",
    "To determine the direction the agent is facing, you need a vector that points from the **center of the agent** to the **edge of its body** in the direction of its current orientation within the environment (`self.orientation`).\n",
    "\n",
    "Here’s how to think about it:\n",
    "\n",
    "- The agent is represented as a circle, but `self.position` gives the **top-left corner** of its bounding box, not the center.\n",
    "- So first, compute the **center position** of the agent (`v1_s_x`, `v1_s_y`):\n",
    "- Then, calculate a point on the **edge of the circle** in the direction the agent is facing (`v1_e_x`, `v1_e_y`):\n",
    "  - Use the variation of `cos(self.orientation)` for the x-direction, and `sin(self.orientation)` for the y-direction.\n",
    "  - Multiply these by the **actual radius** of the agent (since it's not a unit circle)\n",
    "  - (Note: y is subtracted due to screen coordinates increasing downward.)\n",
    "- The difference between this edge point and the center gives you a **heading vector**, which describes where the agent is currently facing:\n",
    "\n",
    "```python\n",
    "  v1_x = v1_e_x - v1_s_x\n",
    "  v1_y = v1_e_y - v1_s_y\n",
    "  heading_vec = np.array([v1_x, v1_y])\n",
    "```\n",
    "\n",
    "🔄 This vector doesn't define velocity or movement. It's purely about orientation and is later used to determine how closely the agent’s actual direction aligns with the direction of a social force, so it will allow us to calculate the change of an agent's heading according to the above model.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Prepare Accumulators for Social Forces**\n",
    "\n",
    "- Initialize the following vectors:\n",
    "  - `vec_attr_total = np.zeros(2)` → for **attraction**\n",
    "  - `vec_rep_total = np.zeros(2)` → for **repulsion**\n",
    "  - `vec_alg_total = np.zeros(2)` → for **alignment**\n",
    "- These will store the total force contributions from all other agents.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Loop Through All Other Agents (`for ag in agents`)**\n",
    "\n",
    "- Skip the agent itself (`if ag.id != self.id:`).\n",
    "- For each neighbor:\n",
    "  - Calculate its **center position** (`ag_pos_x`, `ag_pos_y`).\n",
    "  - Calculate the focal agent’s own center (`v1_s_x`, `v1_s_y` in the previous step).\n",
    "  - Compute the **distance vector** `distvec` between the two with simple subtractions.\n",
    "  - Use either Euclidean distance or `support.distance_infinite()` depending on the boundary condition (`self.boundary`).\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Calculate Velocity Differences (`dvel`)**\n",
    "\n",
    "- Compute the velocity vectors of the focal agent (`s_vel`) and the other agent (`ag_vel`), using their orientation (self.orientation) and speed (self.velocity).\n",
    "- Subtract to get the **velocity difference**: `dvel = ag_vel - s_vel`.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Calculate Individual Social Forces**\n",
    "\n",
    "- For each neighbor, use the appropriate helper function to compute the force based on `distvec` (and `dvel` for alignment):\n",
    "  - `support.CalcSingleAttForce(self.r_att, self.steepness_att, distvec)`\n",
    "  - `support.CalcSingleRepForce(self.r_rep, self.steepness_rep, distvec)`\n",
    "  - `support.CalcSingleAlgForce(self.r_alg, self.steepness_alg, distvec, dvel)`\n",
    "- Add each result to the corresponding total vectors `vec_attr_total`, `vec_rep_total`, `vec_alg_total`.\n",
    "- Explore these helper functions within the support file. What are these?\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Combine the Forces into One (`force_total`)**\n",
    "\n",
    "- Combine the three total force vectors using the zone-specific strengths. Note the signs!\n",
    "\n",
    "---\n",
    "\n",
    "### **7. Convert the Force into a Speed (`vel`) and Turning Angle (`theta`)**\n",
    "\n",
    "- Compute the desired **speed** as a function of the force magnitude:\n",
    "  ```python\n",
    "  vel = self.v_max * np.linalg.norm(force_total)\n",
    "  ```\n",
    "- Compute the **angle** between the agent’s current heading (`heading_vec`) and the new desired direction (`force_total`):\n",
    "  ```python\n",
    "  closed_angle = support.angle_between(heading_vec, force_total)\n",
    "  closed_angle = closed_angle % (2 * np.pi)\n",
    "  ```\n",
    "- Convert `closed_angle` to your simulation's turning convention (`theta`):\n",
    "  - Adjust it to be in `[-π, π]` rather than `[0, 2π]`\n",
    "  - Make sure signs and directions match your orientation system (e.g., 0 radians = facing right)\n",
    "\n",
    "---\n",
    "\n",
    "### **8. Add Directional Noise (Optional)**\n",
    "\n",
    "- If `self.noise_sig > 0.0`, add a small normally distributed value to `theta`\n",
    "\n",
    "---\n",
    "\n",
    "### **9. Store Results for the Next Update Step**\n",
    "\n",
    "- Set the agent’s orientation change (`self.dtheta`) and velocity change (`self.dv`) based on your calculations:\n",
    "  ```python\n",
    "  self.dtheta = theta\n",
    "  self.dv = vel\n",
    "  ```\n",
    "  \n",
    "  \n",
    "**Please modify the code below at the dedicated lines to solve the task accordingly.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0bfb768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pygmodw25.agent import AgentBase\n",
    "\n",
    "class ZonalAgent(AgentBase):\n",
    "    \"\"\"\n",
    "    Agent class that includes all private parameters of the agents and all methods necessary to move in the environment\n",
    "    and to make decisions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, id, radius, position, orientation, env_size, color, window_pad):\n",
    "        \"\"\"\n",
    "        Initalization method of main agent class of the simulations\n",
    "\n",
    "        :param id: ID of agent (int)\n",
    "        :param radius: radius of the agent in pixels\n",
    "        :param position: position of the agent bounding upper left corner in env as (x, y)\n",
    "        :param orientation: absolute orientation of the agent (0 is facing to the right)\n",
    "        :param env_size: environment size available for agents as (width, height)\n",
    "        :param color: color of the agent as (R, G, B)\n",
    "        :param window_pad: padding of the environment in simulation window in pixels\n",
    "        \"\"\"\n",
    "        # Initializing supercalss (Base Agent)\n",
    "        super().__init__(id, radius, position, orientation, env_size, color, window_pad)\n",
    "\n",
    "        # Specifying parameters for this special 3-zone agent\n",
    "        # Interaction strength\n",
    "        # Attraction\n",
    "        self.s_att = 0.02\n",
    "        # Repulsion\n",
    "        self.s_rep = 5\n",
    "        # Alignment\n",
    "        self.s_alg = 8\n",
    "\n",
    "        # Interaction ranges (Zones)\n",
    "        # Attraction\n",
    "        self.steepness_att = -0.5\n",
    "        self.r_att = 250\n",
    "        # Repulsion\n",
    "        self.steepness_rep = -0.5\n",
    "        self.r_rep = 50\n",
    "        # Alignment\n",
    "        self.steepness_alg = -0.5\n",
    "        self.r_alg = 150\n",
    "\n",
    "        # Noise\n",
    "        self.noise_sig = 0.1\n",
    "\n",
    "    def update_forces(self, agents):\n",
    "        \"\"\"Updateing overall social forces on agent according to velocity and distance of others\"\"\"\n",
    "        # CALCULATING change in velocity and orientation in the current timestep\n",
    "        # vel, theta = support.random_walk()\n",
    "        # center point\n",
    "        v1_s_x = self.position[0] + self.radius\n",
    "        v1_s_y = self.position[1] + self.radius\n",
    "\n",
    "        # point on agent's edge circle according to it's orientation\n",
    "        v1_e_x = self.position[0] + (1 + np.cos(self.orientation)) * self.radius\n",
    "        v1_e_y = self.position[1] + (1 - np.sin(self.orientation)) * self.radius\n",
    "\n",
    "        # vector between center and edge according to orientation\n",
    "        v1_x = v1_e_x - v1_s_x\n",
    "        v1_y = v1_e_y - v1_s_y\n",
    "\n",
    "        heading_vec = np.array([v1_x, v1_y])\n",
    "\n",
    "        # CALCULATING attraction force with all agents:\n",
    "        vec_attr_total = np.zeros(2)\n",
    "        vec_rep_total = np.zeros(2)\n",
    "        vec_alg_total = np.zeros(2)\n",
    "        for ag in agents:\n",
    "            if ag.id != self.id:\n",
    "                # Distance between focal agent and given pair\n",
    "                ag_pos_x = ag.position[0] + ag.radius\n",
    "                ag_pos_y = ag.position[1] + ag.radius\n",
    "                s_pos_x = self.position[0] + self.radius\n",
    "                s_pos_y = self.position[1] + self.radius\n",
    "                if self.boundary == \"bounce_back\":\n",
    "                    distvec = np.array([ag_pos_x - s_pos_x, ag_pos_y - s_pos_y])\n",
    "                elif self.boundary == \"infinite\":\n",
    "                    distvec = support.distance_infinite(np.array([s_pos_x, s_pos_y]),\n",
    "                                                        np.array([ag_pos_x, ag_pos_y]))\n",
    "\n",
    "                # Difference between velocity between given agents\n",
    "                s_vel = np.array([self.velocity * np.cos(self.orientation), - self.velocity * np.sin(self.orientation)])\n",
    "                ag_vel = np.array([ag.velocity * np.cos(ag.orientation), - ag.velocity * np.sin(ag.orientation)])\n",
    "                dvel = ag_vel - s_vel\n",
    "\n",
    "                # Calculating interaction forces\n",
    "                vec_attr_total += support.CalcSingleAttForce(self.r_att, self.steepness_att, distvec)\n",
    "                vec_rep_total += support.CalcSingleRepForce(self.r_rep, self.steepness_rep, distvec)\n",
    "                vec_alg_total += support.CalcSingleAlgForce(self.r_alg, self.steepness_alg, distvec, dvel)\n",
    "\n",
    "        force_total = self.s_att * vec_attr_total - self.s_rep * vec_rep_total + self.s_alg * vec_alg_total\n",
    "\n",
    "        vel = self.v_max * np.linalg.norm(force_total)\n",
    "        closed_angle = support.angle_between(heading_vec, force_total)\n",
    "        closed_angle = (closed_angle % (2 * np.pi))\n",
    "        # at this point closed angle between 0 and 2pi, but we need it between -pi and pi\n",
    "        # we also need to take our orientation convention into consideration to recalculate\n",
    "        # theta=0 is pointing to the right\n",
    "        if not np.isnan(closed_angle):\n",
    "            if 0 < closed_angle < np.pi:\n",
    "                theta = -closed_angle\n",
    "            else:\n",
    "                theta = 2 * np.pi - closed_angle\n",
    "        else:\n",
    "            theta = 0\n",
    "\n",
    "        # Adding directional noise\n",
    "        if self.noise_sig > 0.0:\n",
    "            noiseP = np.random.normal(0.0, self.noise_sig, size=1)\n",
    "            theta += noiseP[0]\n",
    "\n",
    "        self.dtheta = theta\n",
    "        self.dv = vel\n",
    "        \n",
    "    def update(self, agents):\n",
    "        self.update_forces(agents)\n",
    "        super().update(agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8956a00",
   "metadata": {},
   "source": [
    "Now try to use your new agent in a simulation by running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86c7d884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation start method!\n",
      "Starting main simulation loop!\n",
      "Bye bye!\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Desktop\\PygameModelling25\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from pygmodw25.sims import Simulation\n",
    "from pygmodw25 import support\n",
    "# Changing simulation such that we use ZonalAgents\n",
    "class ZonalSim(Simulation):\n",
    "    def add_new_agent(self, id, x, y, orient):\n",
    "        \"\"\"Adding a single ZONAL new agent into agent sprites\"\"\"\n",
    "        agent = ZonalAgent(\n",
    "            id=id,\n",
    "            radius=self.agent_radii,\n",
    "            position=(x, y),\n",
    "            orientation=orient,\n",
    "            env_size=(self.WIDTH, self.HEIGHT),\n",
    "            color=support.BLUE,\n",
    "            window_pad=self.window_pad,\n",
    "        )\n",
    "        self.agents.add(agent)\n",
    "        \n",
    "zonal_sim_instance = ZonalSim(N=12, T=300)\n",
    "zonal_sim_instance.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c99bfae",
   "metadata": {},
   "source": [
    "## Task 2: Exploring Zones of Agents\n",
    "\n",
    "Use the code snippet below to run the simulation for only a pair of agents.\n",
    "\n",
    "We turn on the visualization of the local interaction zones by pressing setting the simulation's `show_zones` attribute to 1. If you get the printed message \"Error while drawing agent zones!\" you might have not been keeping the naming of the attributes in the above desrciption.\n",
    "\n",
    "The long-range attraction zone is denoted with a green, the intermediate alignment zone with a yellow and the short-range repulsion with a red circle around the agents. Without pausing the simulation hold one of the agents still with your cursor.  \n",
    "\n",
    "1. How does the other agent react? Is there anything surprising or different than what you expected?\n",
    "2. Why? How can you explain what you see with the effect of the 3 zones (attraction/alignment/repulsion)?\n",
    "3. What happens if you also start rotating the agent at the same time you hold it? Which zone is responsible for the temporary change in the behavior? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aba349",
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_sim_instance = ZonalSim(N=2, T=2500)\n",
    "zonal_sim_instance.show_zones = 1\n",
    "zonal_sim_instance.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b5003d",
   "metadata": {},
   "source": [
    "## Task 3: Understanding Flocking Parameters\n",
    "\n",
    "As we have seen in the introduction to the zonal model each agent has 3 zones of local interaction parametrized by their interaction ranges, steepness parameters and interaction strengths.\n",
    "\n",
    "In the next section we will see how systematically changing these parameters will influence the collective behavior of the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_sim_instance = ZonalSim(N=12, \n",
    "                              T=600, \n",
    "                              width=500,  # Arena width in pixels\n",
    "                              height=500,  # Arena height in pixels\n",
    "                              agent_radius=10,\n",
    "                              physical_obstacle_avoidance=True)\n",
    "\n",
    "# we loop through all the agents of the created simulation and individually change their parameters\n",
    "print(\"Setting parameters for agent\", end = ' ')\n",
    "for agent in zonal_sim_instance.agents:\n",
    "    print(f\"{agent.id}\", end = ', ')\n",
    "    \n",
    "    # changing angular noise (sigma)\n",
    "    agent.noise_sig = 0.1\n",
    "    \n",
    "    # changing their default flocking parameters\n",
    "    agent.s_att = 0.02  # attraction strength (AU)\n",
    "    agent.s_rep = 5  # repulsion strength (AU)\n",
    "    agent.s_alg = 10  # alignment strength (AU)\n",
    "\n",
    "    agent.r_att = 200  # attraction range (px)\n",
    "    agent.r_rep = 50  # repulsion range (px)\n",
    "    agent.r_alg = 100  # alignment range (px)\n",
    "    \n",
    "    agent.steepness_att = -0.5  # steepness in attraction force calculation (sigmoid)\n",
    "    agent.steepness_rep = -0.5  # steepness in repulsion force calculation (sigmoid)\n",
    "    agent.steepness_alg = -0.5  # steepness in alignment force calculation (sigmoid)\n",
    "    \n",
    "    # changing maximum velocity and simulation timesteps\n",
    "    agent.v_max = 2\n",
    "    agent.dt = 0.05\n",
    "    \n",
    "    agent.boundary = \"bounce_back\"\n",
    "    \n",
    "    \n",
    "# Now we can start the simulation with the changed agents\n",
    "zonal_sim_instance.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fabb1a4",
   "metadata": {},
   "source": [
    "Use the example code snippet above and modify it to answer the following questions. \n",
    "\n",
    "1. **Individual Dynamics**: Turn off all the interaction forces. Perform simulations with different angular noise values (noise_sig) and explore the behavior of the agents (you can try: 0.1, 1, 3). For the next tasks fix this parameter to 0.1.\n",
    "2. **Obstacle Avoidance**:\n",
    "    - a. Re-introduce a strong local repulsion interaction (`s_rep = 5`) and by that implement obstacle avoidance in a group of 10 agents. Set the repulsion steepness to -1.\n",
    "    - b. Test the repulsion beahvior with different repulsion ranges (20, 50, 150). Feel free to move around the agents and see what happens when you move them in each others' repulsion zone.\n",
    "    - c. **Hint:** You can visualize the zones around the agents with `z`. Only those zones will be shown for which the corresponding interaction strength is larger than zero. \n",
    "    - d. Explore the effect of the repulsion steepness (-0.1, -0.5, -1). When does repulsion take place with low or high steepness parameter? \n",
    "    - e. Do you think this obstacle avoidance will always avoid agents from collision?\n",
    "    - f. For the upcoming experimentation fix repulsion strength to 5, steepness to -0.5 and range to 50\n",
    " \n",
    "3. **Attraction-Repulsion**\n",
    "    - a. Re-intorduce attraction and explore the beahavior with different attraction strenths 0.05, 0.5, 1, 5.\n",
    "    - b. What happens for attraction strength of 0.05 and 5? What would you consider a realistic attraction strength for a mosquito swarm?\n",
    "    - c. For the next experiment fix the attraction strength to 0.02, attraction range to 200 and steepness to -0.5.\n",
    "    \n",
    "4. **Movement Coordination**\n",
    "    - a. What do you think you will observe when you introduce an intermediate zone where agents align to their neighbors?\n",
    "    - b. Re-introduce the alignment zone by setting a strong alignment strength of 5. Is your observation matching with what you expected? What happens if you increase the attraction strength to 2?\n",
    "    - c. Change back the attraction strength to 0.02. Introduce repellent walls by writing the following in the loop: `agent.boundary = \"bounce_back\"`. Is the system robust enough to handle such perturbations? Try different alignment strengths of 1.75 and 5. What is the difference? Try different angular noise values as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970c3c5",
   "metadata": {},
   "source": [
    "## Task 4.: Heterogeneity (Optional/Home)\n",
    "Now that you know how to change the flocking parameters of the agents we can introduce heterogeneity. \n",
    "\n",
    "Compared to fully idealized model systems, natural groups are heterogenous in terms of some property. Let's suppose in our flock some of the individuals are faster than others.\n",
    "\n",
    "1. Copy the above code snippet and paste it into a new cell in order to model a swarm of 20 agents from which half is 10% faster than the other half? You can control the agents' speed with their `v_max` attribute. (**Hint:** You can change the color of the fast agents by setting their `orig_color` attribute to any RGB tuple `(R, G, B)` where R, G, B are integers between 0 and 255).\n",
    "2. Do you see any effect of such a heterogeneity?\n",
    "3. What happens when the fast agents are twice as fast as the slow agents (e.g. `v_max=2` and `v_max=1` respectively)? What do you see?\n",
    "4. Heterogeneity in natural systems are usually on a spectrum and the difference is not binary (fast/slow). Set the maximum velocity of agents in the group as a random uniform distribution between 1 and 2.5. Set the color of the agents in a way that they give useful information about their maximum speed.\n",
    "5. You can use 30 agents and set the arena to 700x700. Set the boundary condition of the agents to `\"bounce_back\"` so that they can not cross walls.\n",
    "6. What do you observe?\n",
    "7. Is the obstacle avoidance (strong repulsion force) always successful in large groups? Pygame provides useful implementation of [collision groups](https://stackoverflow.com/questions/29640685/how-do-i-detect-collision-in-pygame). Turn on pygame-based obstacle avoidance by adding `physical_obstacle_avoidance=True` in the argment when creating your `Simulation` class instance. Did anything change in the effect you have observed in 4.6.?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfe859d",
   "metadata": {},
   "source": [
    "## Task 5.: Modelling epidemic spread of disease with the SIR model (Optional/Home)\n",
    "\n",
    "In the [SIR model](https://de.wikipedia.org/wiki/SIR-Modell) of disease spread agents have 3 basic states of infection. When agents have not yet contacted the disease they are susceptible for a possible infection ($S$). When they get infected ($I$) they can spread the disease to other susceptible agents in a given infection radius ($R_I$) with probability ($P_I$). In our immplementation, agents can only come out from an infected state 2 way (note that this can vary across model implementations). They either recover ($R$) with probability $P_R$ and get immune to future infections, or they die ($D$) with probability $P_D$)\n",
    "\n",
    "**Task:**\n",
    "Implement this model by extending the `AgentBase` class:\n",
    "* Each agent should have the SIR model parameters as attributes, such as probabilities for infection, recovery and death\n",
    "* They should have a `state` attribute being one of the following 4 states: S, I, R or D\n",
    "* Override the `update`method such that it includes a probabilistic state change according to the above rules.\n",
    "* If agents are susceptible, they should be blue\n",
    "* Infected agents should turn red\n",
    "* Recovered agents are green\n",
    "* Agents that are dead should stop moving and turn grey.\n",
    "\n",
    "Creat a new `SIRSimulation` class that uses these agents and start the simulation. \n",
    "\n",
    "**Optional/Pro:** \n",
    "* Implement data saving, by overriding the `BridgeIO` method of the `SIRSimulation` class, such that\n",
    "    * In each simulation step the `SIRSimulation` class saves internally how many agents of different state there are within the simulation.\n",
    "    * In the last timestep it writes these arrays into files\n",
    "* Use matplotlib to plot these and see how the different probabilities change the model outcomes. They should look similar to this plot:\n",
    "\n",
    "<img src=\"data/images/SIREvolution.png\">\n",
    "\n",
    "**Figure3.:** Example of the 3 interaction zones around a focal agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979c799",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "During the next session we will connect the flocking model we created to the mixed-reality system at our cluster, called CoBeXR (https://www.biorxiv.org/content/10.1101/2025.06.15.659521v1). This system creates a loop from tracked human action - through simulation - to visualization. In sum, it allows you to track an embodied physical object, e.g. a tracking cane, and change a simulated world according to its movement, which then in real time projected back to the arena. This allows a quick experimentation with computational models among many other applications.\n",
    "\n",
    "To connect your model with the system, on the other hand, you will have to connect it to CoBeXR through file read and write commands (so called IO Bridge). This concept is very simple, you can think of it, as the tracking system writes the position of the tracked object into a file. Your simulation needs to read it, interpret it and change the simulation accordingly in every timestep.\n",
    "\n",
    "**For example:** You can set up the system to track your hand and write it's 3D position into a selected file. Your simulation could, for instance read this file and according to it's Z coordinate, change the movement noise of the agents (`agent.noise_sig` between 0 and 1). As a result, moving the tracked object in the arena up and down (in this case your hand), would allow a real-time experimentation of the change of this parameter.\n",
    "\n",
    "Your task is to create such an IO Bridge so we can connect your model to the system. You are free to think of what would you like to change in the model according to the tracked object's physical position. Examples can be the actual position of one of the agents, system parameters, such as agents' speed, behavioral parameters such as attrcation strength, visualization, such as colors, etc. For those who want more challenge and fun, you can also implement the SIR model (as above) and control infection parameters, or create a super-infectious agent that follows the tracked object (getting close to gamification).\n",
    "\n",
    "To create the IOBridge, please create a new `CoBeSimulation` class (inheriting from `ZonalSim`, or the SIR simulation for advanced case) and without any further change you have to override it's `bridgeIO` method. You can find the pseudocode below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079c9936",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "\n",
    "class CoBeSimulation(ZonalSim):\n",
    "    def bridgeIO(self):\n",
    "        ### DEFINE THE PATH OF THE FILE TO BE READ\n",
    "        \n",
    "        ### READ JSON FILE HERE\n",
    "            ## check if file exists and accessible\n",
    "            ## if yes, open and read\n",
    "        \n",
    "        ### INTERPRET THE READ VALUE HERE\n",
    "        ### AND APPLY CHANGES TO AGENTS/SIMULATION PARAMETERS\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f06363d",
   "metadata": {},
   "source": [
    "**Specification:** \n",
    "* The file to be read is a json file\n",
    "* The location of the file is the working folder and has a name `bridge.json`\n",
    "* The file contains a list, where each element has an ID key containing the ID of the tracked objects and its x, y, z position of the tracked object in the arena.\n",
    "* You can have zero, one or many objects tracked (optional, must work for one or zero)\n",
    "* The content of an example file looks like this:\n",
    "\n",
    "```json\n",
    "[{\"ID\": 1, \"x\": 1391, \"y\": -4166, \"z\": 1249}]\n",
    "```\n",
    "\n",
    "* the maximum absolute coordinates both in x and y are 3500mm (can be +-)\n",
    "* the maximum coordinates in z is expcted to be around 3000mm\n",
    "* in case you get larger numbers truncate these to the maximum (or minimum) values\n",
    "\n",
    "**Definition of Done:**\n",
    "Your simulation changes a single parameter visibly when the file has been changed during simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd50d09-6ce3-470e-b908-de531d203959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you assignment here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e94b2049-8194-448e-9469-5c4aea7ada99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation start method!\n",
      "Starting main simulation loop!\n",
      "Bye bye!\n"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "cobe_sim = CoBeSimulation(N=10, T=500)\n",
    "cobe_sim.show_zones = 1\n",
    "cobe_sim.initiate_mixed_reality()\n",
    "try:\n",
    "    cobe_sim.start()\n",
    "except:\n",
    "    pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb56a716-72cb-4bfa-8341-e3974f698aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
